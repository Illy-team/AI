{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d0fef-59c5-41f6-b73a-94be81e59403",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CSV 파일 경로 지정\n",
    "csv_file_path = '/Users/jhkim97/Downloads/translated-contest-output.csv'\n",
    "\n",
    "# CSV 파일 읽어오기\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# 정제된 데이터를 저장할 새로운 DataFrame 생성\n",
    "cleaned_df = df.copy()\n",
    "\n",
    "# 정규 표현식을 사용하여 특수문자 제거\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # 영어, 숫자, 한글, 공백을 제외한 모든 문자를 제거\n",
    "        cleaned_text = re.sub(r'[^a-zA-Z0-9가-힣\\s]', '', text)\n",
    "        return cleaned_text\n",
    "    else:\n",
    "        # 문자열이 아닌 경우 그대로 반환\n",
    "        return text\n",
    "\n",
    "# 모든 셀에 대해 특수문자 제거 함수를 적용\n",
    "for column in cleaned_df.columns:\n",
    "    cleaned_df[column] = cleaned_df[column].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86955b-7cfd-4970-a28a-752e09cc6794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "\n",
    "top_10_similarities = []\n",
    "\n",
    "# contest_output.csv 파일에서 데이터 읽어오기\n",
    "# 가정: cleaned_df는 이미 'contest' 데이터를 포함하고 있음\n",
    "data = cleaned_df\n",
    "data['preferred'].fillna(\"hello\", inplace=True)\n",
    "data['requirement'].fillna(\"hello\", inplace=True)  # 'preferred', 'requirement' 컬럼에 누락된 값이 있을 경우 기본값으로 채움\n",
    "\n",
    "# IT 포트폴리오 데이터 읽어오기\n",
    "it_portfolio_df = pd.read_csv('/Users/jhkim97/Downloads/userid_1_filtered_correct_data.csv')  # 파일 경로 수정 필요\n",
    "\n",
    "# 모델 및 토크나이저 불러오기\n",
    "model_name = \"jjzha/jobspanbert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# IT 포트폴리오 데이터를 기반으로 유사도 측정\n",
    "for index, row in it_portfolio_df.iterrows():\n",
    "    role_text = row['Role']\n",
    "    project_title_text = row['ProjectTitle']\n",
    "    technology_text = row['Technology']\n",
    "\n",
    "    # IT 포트폴리오 데이터를 하나의 텍스트로 합치기\n",
    "    it_portfolio_text = f\"{role_text}. {project_title_text}. {technology_text}\"\n",
    "\n",
    "    # 포트폴리오 텍스트 토큰화 및 인덱싱\n",
    "    user_inputs = tokenizer(it_portfolio_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    # contest 데이터를 처리하고 모델에 입력으로 전달\n",
    "    combined_embeddings = []\n",
    "\n",
    "    for idx, contest_row in data.iterrows():\n",
    "        requirement_text = contest_row['requirement']\n",
    "        preferred_text = contest_row['preferred']\n",
    "        category_text = str(contest_row['category'])  # category_text가 단일 객체인 경우 문자열로 변환\n",
    "\n",
    "        # 텍스트 토큰화 및 인덱싱\n",
    "        requirement_inputs = tokenizer(requirement_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        preferred_inputs = tokenizer(preferred_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        category_inputs = tokenizer(category_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "        # 모델에 전달하여 임베딩 얻기\n",
    "        requirement_outputs = model(**requirement_inputs)\n",
    "        preferred_outputs = model(**preferred_inputs)\n",
    "        category_outputs = model(**category_inputs)\n",
    "\n",
    "        # 임베딩을 합치기\n",
    "        combined_requirement_embedding = requirement_outputs.last_hidden_state[:, 0, :]\n",
    "        combined_preferred_embedding = preferred_outputs.last_hidden_state[:, 0, :]\n",
    "        combined_category_embedding = category_outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        # 가중치를 적용하여 임베딩 결합\n",
    "        weighted_combined_embedding = (0.4 * combined_requirement_embedding + 0.5 * combined_preferred_embedding + 0.3 * combined_category_embedding) / 1.2\n",
    "\n",
    "        combined_embeddings.append(weighted_combined_embedding)\n",
    "\n",
    "    # IT 포트폴리오 텍스트의 임베딩 얻기\n",
    "    it_portfolio_embedding = model(**user_inputs).last_hidden_state[:, 0, :]\n",
    "\n",
    "    # 각 요구사항, 선호사항 및 category와 IT 포트폴리오 간의 가중치 적용된 코사인 유사도 계산\n",
    "    similarities = [1 - cosine(it_portfolio_embedding.detach().numpy().flatten(), weighted_combined_embedding.detach().numpy().flatten()) for weighted_combined_embedding in combined_embeddings]\n",
    "\n",
    "    # 유사도를 기준으로 상위 10개 contest를 저장\n",
    "    top_10_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:10]\n",
    "    top_10_contests = [(contest_index, similarities[contest_index]) for contest_index in top_10_indices]\n",
    "    top_10_similarities.append((it_portfolio_text, top_10_contests))\n",
    "\n",
    "\n",
    "    # 상위 10개 유사도를 출력\n",
    "    for idx, (portfolio_text, top_10_activities) in enumerate(top_10_similarities):\n",
    "        print(f\"IT Portfolio {idx + 1}:\")\n",
    "    for activity_index, similarity in top_10_contests:\n",
    "        print(f\"  - Contest {contest_index + 169}, Similarity: {similarity:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
